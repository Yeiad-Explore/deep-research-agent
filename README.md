# ğŸ”¬ Deep Research Agent

AI-powered deep web research agent combining LangGraph orchestration, Tavily AI Search, and Azure OpenAI GPT-5.1 for comprehensive web research and synthesis.

## ğŸŒŸ Features

- **Deep Web Research**: Comprehensive web search and content analysis
- **LangGraph Orchestration**: Sophisticated AI workflow with parallel execution
- **Tavily AI Search**: AI-optimized web search specifically designed for LLM applications
- **Real-Time Streaming**: WebSocket-based progress updates
- **Cross-Reference Validation**: Verifies facts across multiple web sources
- **Comprehensive Reports**: Generates detailed research syntheses with citations
- **Interactive UI**: Modern, responsive interface with live updates
- **Modern Frontend**: Next.js frontend with shadcn/ui, animations, and better UX

## ğŸ“‹ Prerequisites

- Python 3.9+
- API Keys:
  - Tavily AI API key (for web search)
  - Azure OpenAI API credentials (GPT-5.1)

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
cd "deepresearch agent"
```

### 2. Set Up Backend

```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment variables
cp .env.example .env
# Edit .env with your API keys
```

### 3. Configure API Keys

Edit `backend/.env` and add your API credentials:

```env
# Tavily AI Search Configuration
TAVILY_API_KEY=your_tavily_api_key_here

# Azure OpenAI Configuration (GPT-5.1 for all LLM operations)
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=https://your-endpoint.cognitiveservices.azure.com/openai/v1
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-5.1-chat

# Application Configuration
CORS_ORIGINS=http://localhost:3000,http://localhost:8000
MAX_ITERATIONS=3
DEFAULT_SEARCH_RESULTS=15
```

**Important Notes:**
- **Tavily AI** provides AI-optimized search results with up to 20 results in advanced mode
- **GPT-5.1** only supports `temperature=1` and uses `max_completion_tokens` parameter

### 4. Run the Application

**Using startup scripts:**

Windows:
```bash
# From project root
.\start.bat
```

macOS/Linux:
```bash
# From project root
chmod +x start.sh
./start.sh
```

**Manual start:**
```bash
# From the backend directory
python -m uvicorn app.main:app --reload --host 127.0.0.1 --port 8000
```

### 5. Set Up Frontend (Optional - Modern Next.js Frontend)

The project includes two frontend options:

**Option A: Modern Next.js Frontend (Recommended)**
```bash
cd frontend-nextjs
npm install
npm run dev
```

The Next.js frontend will be available at: http://localhost:3000

**Option B: Legacy HTML Frontend**

The application will be available at:
- Frontend: http://localhost:8000 (served by FastAPI)
- API Docs: http://localhost:8000/docs

**Note:** The backend CORS is configured to allow both `http://localhost:3000` (Next.js) and `http://localhost:8000` (legacy frontend).

## ğŸ“š API Documentation

### POST /api/research

Start a new research session.

**Request:**
```json
{
  "query": "What are the latest developments in Python 3.13?",
  "config": {
    "depth": "standard",
    "max_iterations": 3,
    "max_web_results": 15
  }
}
```

**Response:**
```json
{
  "session_id": "uuid",
  "query": "...",
  "response": "...",
  "sources": [...],
  "timestamp": "..."
}
```

### WebSocket /ws/research

Real-time streaming research with progress updates.

**Connect:**
```javascript
const ws = new WebSocket('ws://localhost:8000/ws/research');

ws.send(JSON.stringify({
  query: "your research query",
  config: { depth: "standard", max_web_results: 15 }
}));

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Progress update:', data);
};
```

### GET /api/research/{session_id}

Retrieve a completed research session.

### POST /api/research/{session_id}/refine

Refine existing research with additional focus.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Backend                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   LangGraph  â”‚  â”‚  Tavily AI   â”‚  â”‚ Azure OpenAI â”‚ â”‚
â”‚  â”‚ Orchestrator â”‚  â”‚    Search    â”‚  â”‚  GPT-5.1     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ Web Scraper  â”‚  â”‚   Research   â”‚                    â”‚
â”‚  â”‚              â”‚  â”‚     Tools    â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Next.js Frontend                            â”‚
â”‚  WebSocket Streaming â€¢ Live Updates â€¢ Export Features   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Research Workflow

The research process follows a LangGraph state machine with 4 optimized nodes:

1. **Query Planner**: Analyzes query and creates research strategy
   - Generates optimal search keywords
   - Plans research approach

2. **Web Searcher**: Searches the web using Tavily AI
   - Tavily AI web search (advanced mode)
   - Returns up to 20 high-quality results

3. **Content Scraper**: Gathers content from URLs
   - Web page scraping with BeautifulSoup
   - Content extraction and cleaning
   - **All scraping tasks run in parallel**

4. **Answer Generator**: Generates comprehensive answer
   - Combines all scraped web content
   - Uses Azure OpenAI GPT-5.1 for synthesis
   - Structures findings with citations
   - Creates detailed research answer

### Performance Optimizations

The workflow is optimized for speed:

- **Parallel execution**: All I/O-bound operations use `asyncio.gather()` for concurrent execution
- **Efficient scraping**: Multiple URLs scraped simultaneously
- **Reduced defaults**: Optimized iteration count and result limits for faster results
- **Recursion limit**: Set to 100 to support multiple iterations without errors

## ğŸ¯ Use Cases

- **Product Research**: Web specs + Reddit user reviews
- **Technical Topics**: Documentation + developer discussions
- **Current Events**: News + community reactions
- **Comparative Analysis**: Professional reviews + user experiences
- **Troubleshooting**: Official docs + Reddit solutions
- **Market Research**: Industry reports + community sentiment
- **Technology Evaluation**: Technical docs + real-world experiences

## ğŸ“¦ Project Structure

```
deepresearch agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI entry point
â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration (Pydantic Settings)
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic models & TypedDict
â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â”œâ”€â”€ graph_builder.py    # LangGraph construction
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes.py            # Research agent nodes
â”‚   â”‚   â”‚   â””â”€â”€ tools.py            # Research tools
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ tavily_client.py    # Tavily AI Search client
â”‚   â”‚   â”‚   â””â”€â”€ azure_client.py     # Azure OpenAI GPT-5.1 client
â”‚   â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”‚   â””â”€â”€ web_scraper.py      # Web scraper (aiohttp)
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â””â”€â”€ routes.py           # API endpoints & WebSocket
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ .env                        # Your API keys (create this)
â”œâ”€â”€ frontend/                        # Legacy HTML/CSS/JS frontend
â”‚   â”œâ”€â”€ index.html                  # Main UI
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ styles.css
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ main.js                 # Application logic
â”‚       â”œâ”€â”€ api.js                  # API client
â”‚       â””â”€â”€ ui.js                   # UI updates
â”œâ”€â”€ frontend-nextjs/                 # Modern Next.js frontend (Recommended)
â”‚   â”œâ”€â”€ app/                        # Next.js app directory
â”‚   â”œâ”€â”€ components/                 # React components
â”‚   â”‚   â”œâ”€â”€ ui/                     # shadcn/ui components
â”‚   â”‚   â””â”€â”€ research/               # Research-specific components
â”‚   â”œâ”€â”€ lib/                        # Utilities and API client
â”‚   â”œâ”€â”€ types/                      # TypeScript types
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ plan.md                         # Original project plan
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ ARCHITECTURE.tex                # System architecture (LaTeX)
â”œâ”€â”€ start.bat                       # Windows startup script
â””â”€â”€ start.sh                        # Unix startup script
```

## ğŸ”§ Configuration Options

### Research Depth
- **Quick**: 1-2 iterations, faster results
- **Standard**: 2-3 iterations, balanced (default)
- **Comprehensive**: 3-5 iterations, thorough research

### Web Search Options
- Number of results (default: 15, max: 20 for advanced)
- Search depth: basic or advanced (Tavily)
- Domain filtering (include/exclude specific domains)

### Scraping Options
- Timeout settings
- Maximum content length
- Retry configuration with exponential backoff

## ğŸ› ï¸ Development

### Technology Stack

**Backend:**
- FastAPI - Modern async web framework
- LangGraph - AI agent orchestration
- Tavily Python - AI-optimized search
- OpenAI Python SDK - Azure OpenAI integration
- Pydantic - Data validation and settings
- aiohttp - Async HTTP client
- BeautifulSoup4 - Web scraping
- Tenacity - Retry logic

**Frontend:**
- **Next.js 14** - Modern React framework with App Router
- **React 18** - UI library with TypeScript
- **shadcn/ui** - High-quality component library
- **Tailwind CSS** - Utility-first CSS framework
- **Framer Motion** - Smooth animations and transitions
- **WebSocket API** - Real-time communication
- Legacy HTML/CSS/JS frontend also available in `frontend/` directory

### Adding New LLM Providers

Create a new client in `backend/app/llm/`:

```python
class NewLLMClient:
    async def chat_completion(self, messages, max_completion_tokens=2000):
        # Implementation
        pass
```

### Adding New Data Sources

1. Create scraper in `backend/app/scrapers/`
2. Add tool method in `backend/app/agents/tools.py`
3. Integrate into research nodes in `backend/app/agents/nodes.py`

### Customizing Research Nodes

Modify nodes in `backend/app/agents/nodes.py`:

```python
async def custom_node(self, state: ResearchState) -> ResearchState:
    # Your custom logic
    state["custom_data"] = result
    return state
```

Add to graph in `backend/app/agents/graph_builder.py`:

```python
workflow.add_node("custom_node", nodes.custom_node)
workflow.add_edge("previous_node", "custom_node")
```

## ğŸ› Troubleshooting

### WebSocket Connection Issues

If WebSocket streaming doesn't work:
1. Check CORS settings in `config.py`
2. Ensure port 8000 is accessible
3. Verify no firewall blocking
4. Check browser console for errors
5. Try using HTTP fallback (POST /api/research)

### Tavily API Errors

**Error: 401 Unauthorized**
- Verify your Tavily API key is correct
- Check your account has credits

**Error: Rate limit exceeded**
- Tavily has monthly request limits
- Reduce `max_web_results` in config
- Wait and retry

### Azure OpenAI Errors

**Error: Unsupported parameter 'temperature'**
- GPT-5.1 only supports temperature=1.0 (default)
- This has been fixed in the latest version

**Error: Unsupported parameter 'max_tokens'**
- GPT-5.1 uses `max_completion_tokens` instead
- This has been fixed in the latest version

### Rate Limiting

The application includes:
- Automatic retries with exponential backoff (via Tenacity)
- Configurable timeout settings
- Error handling for rate limit scenarios

## ğŸ”’ Security Considerations

- API keys are stored in `.env` (never commit this file)
- CORS is configured for localhost only by default
- Web scraping respects robots.txt
- Rate limiting prevents API abuse
- Input validation via Pydantic models

## ğŸ“Š Performance Tips

1. **Reduce iterations** for faster results (1-2 instead of 3-5)
2. **Limit sources**: Fewer web results = faster processing
3. **Use Quick depth** for simple queries
4. **Adjust max_web_results** based on your needs (default: 15)

## ğŸ§ª Testing

The application includes error handling and logging:

```bash
# Check logs for debugging
tail -f backend/app.log  # On Unix
type backend\app.log     # On Windows
```

Test individual components:

```python
# Test Tavily search
from app.llm.tavily_client import TavilySearchClient
client = TavilySearchClient(api_key="your_key")
results = await client.web_search("test query")
```

## ğŸ“„ License

This project is provided as-is for educational and research purposes.

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

Areas for contribution:
- Additional data sources
- New LLM providers
- Enhanced UI features
- Performance optimizations
- Documentation improvements

## ğŸ“§ Support

For issues and questions, please create an issue in the repository.

## ğŸ™ Acknowledgments

- **LangGraph** by LangChain - AI agent orchestration
- **Tavily AI** - AI-optimized search API
- **Azure OpenAI** - GPT-5.1 language model
- **FastAPI** - Modern Python web framework

## ğŸ“ˆ Roadmap

- [ ] Support for additional LLM providers (Anthropic, Google)
- [ ] Database for research session persistence
- [ ] Export to multiple formats (PDF, Markdown, JSON)
- [ ] Advanced filtering and search within results
- [ ] User authentication and saved searches
- [ ] Scheduled/automated research runs
- [ ] API rate limit monitoring dashboard
- [ ] Multi-language support

---

**Built with**: LangGraph â€¢ Tavily AI â€¢ Azure OpenAI GPT-5.1 â€¢ FastAPI â€¢ Next.js

**Version**: 1.0.0
**Last Updated**: December 2025
